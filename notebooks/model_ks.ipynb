{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple predictions of successful funding - logistic regression\n",
    "\n",
    "### _Lukas Vlcek_\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Kickstarter records contain more than 200,000 projects, with information about the ultimate success or failure of their funding campaign, the type of the proposed work, country of origin, or amounts of money asked and pledged by funders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe from a pre-processed CSV file and filter out uninformative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_path = '../data/processed'\n",
    "report_path = '../reports'\n",
    "filename = 'kick_id.csv'\n",
    "datecols = ['created_at', 'deadline', 'state_changed_at', 'launched_at']\n",
    "fdatpars = lambda x: datetime.datetime.fromtimestamp(int(x)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "df = pd.read_csv(os.path.join(target_path, filename), index_col='id', parse_dates=datecols, date_parser=fdatpars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out unneeded data and add some indicator features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149007,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['disable_communication'], axis='columns')\n",
    "df = df.loc[(df['state'] != 'live') & (df['state'] != 'suspended')]\n",
    "cat_type = [x.split('/')[0] for x in df['category'].values]\n",
    "df['cat_type'] = np.array(cat_type)\n",
    "df['dummy'] = 1\n",
    "df['period'] = (df['launched_at'] >= '2014-06-01') & (df['launched_at'] < '2018-01-01')\n",
    "df['succeeded'] = np.int_(df['state'] == 'successful')\n",
    "df['staff_pick'] = np.int_(df['staff_pick'])\n",
    "df.sort_values('launched_at').loc[df.period]['launched_at'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting words in project names and blurbs\n",
    "df.loc[df['blurb'].isnull(), 'blurb'] = ''\n",
    "df.loc[df['name'].isnull(), 'name'] = ''\n",
    "df['blurb_wlen'] = df['blurb'].str.split().apply(len)\n",
    "df['name_wlen'] = df['name'].str.split().apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((149007, 23), (89449, 23))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make new dataframes with new and old data\n",
    "dfn = df.loc[df.period].copy()\n",
    "dfo = df.loc[~df.period].copy()\n",
    "dfn.shape, dfo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn['goal_log'] = np.log10(dfn['goal'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = dfn.drop(['usd_pledged','goal','state','slug','currency','deadline','state_changed_at','created_at','backers_count','spotlight','period'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pledged</th>\n",
       "      <th>country</th>\n",
       "      <th>launched_at</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>blurb</th>\n",
       "      <th>category</th>\n",
       "      <th>cat_type</th>\n",
       "      <th>dummy</th>\n",
       "      <th>succeeded</th>\n",
       "      <th>blurb_wlen</th>\n",
       "      <th>name_wlen</th>\n",
       "      <th>goal_log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18520</th>\n",
       "      <td>Grandma's are Life</td>\n",
       "      <td>62.0</td>\n",
       "      <td>US</td>\n",
       "      <td>2016-10-19 09:32:40</td>\n",
       "      <td>0</td>\n",
       "      <td>Raising money to help my grandmother recover f...</td>\n",
       "      <td>music/world music</td>\n",
       "      <td>music</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>4.176091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21109</th>\n",
       "      <td>Meta</td>\n",
       "      <td>173.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>2015-04-07 18:37:44</td>\n",
       "      <td>0</td>\n",
       "      <td>My work is performance based but I branch out ...</td>\n",
       "      <td>art/performance art</td>\n",
       "      <td>art</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2.176091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24380</th>\n",
       "      <td>Puss N' Books: A relaxing cat cafe and bookstore.</td>\n",
       "      <td>776.0</td>\n",
       "      <td>US</td>\n",
       "      <td>2015-10-27 11:25:33</td>\n",
       "      <td>0</td>\n",
       "      <td>A sanctuary for humans and felines alike! Come...</td>\n",
       "      <td>food/spaces</td>\n",
       "      <td>food</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>4.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33867</th>\n",
       "      <td>TASTE MAKERS BY TRISH P</td>\n",
       "      <td>2798.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>2015-06-15 14:28:11</td>\n",
       "      <td>1</td>\n",
       "      <td>Taste Makers is a socially conscious brand tha...</td>\n",
       "      <td>fashion/ready-to-wear</td>\n",
       "      <td>fashion</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>4.255273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39036</th>\n",
       "      <td>The Meat Candy Experience</td>\n",
       "      <td>3239.0</td>\n",
       "      <td>US</td>\n",
       "      <td>2016-05-16 18:34:18</td>\n",
       "      <td>0</td>\n",
       "      <td>The BEST beef sticks, beef jerky and signature...</td>\n",
       "      <td>food/small batch</td>\n",
       "      <td>food</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>3.397940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  pledged country  \\\n",
       "id                                                                          \n",
       "18520                                 Grandma's are Life     62.0      US   \n",
       "21109                                               Meta    173.0      GB   \n",
       "24380  Puss N' Books: A relaxing cat cafe and bookstore.    776.0      US   \n",
       "33867                            TASTE MAKERS BY TRISH P   2798.0      CA   \n",
       "39036                          The Meat Candy Experience   3239.0      US   \n",
       "\n",
       "              launched_at  staff_pick  \\\n",
       "id                                      \n",
       "18520 2016-10-19 09:32:40           0   \n",
       "21109 2015-04-07 18:37:44           0   \n",
       "24380 2015-10-27 11:25:33           0   \n",
       "33867 2015-06-15 14:28:11           1   \n",
       "39036 2016-05-16 18:34:18           0   \n",
       "\n",
       "                                                   blurb  \\\n",
       "id                                                         \n",
       "18520  Raising money to help my grandmother recover f...   \n",
       "21109  My work is performance based but I branch out ...   \n",
       "24380  A sanctuary for humans and felines alike! Come...   \n",
       "33867  Taste Makers is a socially conscious brand tha...   \n",
       "39036  The BEST beef sticks, beef jerky and signature...   \n",
       "\n",
       "                    category cat_type  dummy  succeeded  blurb_wlen  \\\n",
       "id                                                                    \n",
       "18520      music/world music    music      1          0          24   \n",
       "21109    art/performance art      art      1          1          24   \n",
       "24380            food/spaces     food      1          0          24   \n",
       "33867  fashion/ready-to-wear  fashion      1          0          23   \n",
       "39036       food/small batch     food      1          1          13   \n",
       "\n",
       "       name_wlen  goal_log  \n",
       "id                          \n",
       "18520          3  4.176091  \n",
       "21109          1  2.176091  \n",
       "24380          9  4.301030  \n",
       "33867          5  4.255273  \n",
       "39036          4  3.397940  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies\n",
    "dfd = pd.get_dummies(dfm, columns=['country','cat_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ML imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Training and testing data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=dfd.sample(frac=0.8,random_state=200)\n",
    "df_test=dfd.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119206, 48) (29801, 48) (149007, 48)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape, dfd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train Naive Bayes on name and blurb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119206, 24661) (119206, 35717) (119206,)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=2, max_df=2000)\n",
    "\n",
    "# project name\n",
    "Xn = vectorizer.fit_transform(df_train.name).tocsc()\n",
    "#fn_names = vectorizer.get_feature_names()\n",
    "\n",
    "# project blurb\n",
    "dfn.blurb.fillna('', inplace=True)\n",
    "Xb = vectorizer.fit_transform(df_train.blurb).tocsc()\n",
    "#fb_names = vectorizer.get_feature_names()\n",
    "\n",
    "y = df_train.succeeded.values.astype(np.int)\n",
    "\n",
    "print(Xn.shape, Xb.shape, y.shape)#, len(fn_names), len(fb_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha {'alpha': 1.2589254117941673}\n",
      "Best score 0.670410885358\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best alpha {'alpha': 1.2589254117941673}\n",
      "Best score 0.688857943392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    3.4s finished\n"
     ]
    }
   ],
   "source": [
    "#the grid of parameters to search over\n",
    "param_grid = {'alpha':np.logspace(0.1, 100, 10)}\n",
    "              \n",
    "#mnb = BernoulliNB()\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "mnb_cv = GridSearchCV(mnb, param_grid, cv=5, verbose=1)\n",
    "\n",
    "# train and predict names\n",
    "mnb_cv.fit(Xn, y)\n",
    "pn = mnb_cv.predict_proba(Xn)[:,1]\n",
    "print('Best alpha', mnb_cv.best_params_)\n",
    "print('Best score', mnb_cv.best_score_)\n",
    "\n",
    "# train and predict blurbs\n",
    "mnb_cv.fit(Xb, y)\n",
    "pb = mnb_cv.predict_proba(Xb)[:,1]\n",
    "print('Best alpha', mnb_cv.best_params_)\n",
    "print('Best score', mnb_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['xn'] = np.log(pn/(1-pn))\n",
    "df_train['xb'] = np.log(pb/(1-pb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = []\n",
    "predictors.extend([c for c in dfd.columns if c[0:5] == 'cat_t' ])\n",
    "predictors.extend([c for c in dfd.columns if c[0:5] == 'count' ])\n",
    "#predictors.extend(['goal_log', 'staff_pick','name_wlen', 'xn', 'xb'])\n",
    "predictors.extend(['goal_log', 'staff_pick','name_wlen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = df_train[predictors]\n",
    "ytrain = df_train.succeeded.values.astype(np.int)\n",
    "\n",
    "#Xtrain, Xtest, ytrain, ytest = train_test_split(X, y)\n",
    "#print(X.shape, Xtrain.shape, Xtest.shape, y.shape, ytrain.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][ 1.67239501] [[ -1.54736975e-01   6.37432018e-01  -4.03178109e-01   8.45905186e-01\n",
      "    1.66575366e+00  -3.16567970e-01   4.84352258e-01  -6.57644904e-01\n",
      "    6.22206615e-01  -9.55272598e-01   3.05443063e-01  -4.54812311e-01\n",
      "   -1.33105993e-01  -5.28125807e-01   7.14746879e-01  -7.80630645e-01\n",
      "   -2.10838961e-01  -4.71180303e-01  -1.28053319e-01  -9.54382725e-03\n",
      "   -5.07508715e-01   6.00849087e-01  -5.46777488e-01  -7.56966802e-04\n",
      "   -9.82509122e-02   1.51149337e+00  -2.33190893e-01  -9.42242091e-01\n",
      "    1.37968505e+00   7.39903953e-01   3.66693962e-01  -5.05469927e-01\n",
      "    3.68768078e-01   7.66430786e-02   6.38788966e-01   4.40825746e-01\n",
      "   -1.68122231e-02  -8.37906138e-01   2.54708466e+00   1.13502357e-01]]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(verbose=1, C=1e6)#, warm_start=True)\n",
    "\n",
    "#print(logreg.intercept_, logreg.coef_)\n",
    "logreg.fit(Xtrain, ytrain)\n",
    "#logreg.intercept_ = 2.299\n",
    "#logreg.coef_ = np.reshape(np.array([-0.6687]), (1,-1))\n",
    "print(logreg.intercept_, logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.724971897388\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(Xtrain)\n",
    "y_pred_prob = logreg.predict_proba(Xtrain)\n",
    "print('Score:', logreg.score(Xtrain, ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]CV score: [ 0.72758158  0.72183542  0.72266264  0.72668932  0.72508389]\n"
     ]
    }
   ],
   "source": [
    "print('CV score:', cross_val_score(logreg, Xtrain, ytrain, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f263c464ec9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#y_pred_cv = cross_val_predict(logreg, X, y, cv=3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#y_pred_cv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xtest' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(Xtest)\n",
    "y_pred_prob = logreg.predict_proba(Xtest)\n",
    "print('Score:', logreg.score(Xtest, ytest))\n",
    "#y_pred_cv = cross_val_predict(logreg, X, y, cv=3)\n",
    "#y_pred_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ytest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-9f8216b9eb01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FPR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TPR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ytest' is not defined"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(ytest, y_pred_prob[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title(\"ROC\")\n",
    "print('AUC', roc_auc_score(ytest, y_pred_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregcv = LogisticRegressionCV(verbose=1, cv=3, Cs=[0.1, 1.0, 100.0])#, warm_start=True)\n",
    "logregcv.fit(X, y)\n",
    "print(logregcv.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logregcv.predict(Xtest)\n",
    "y_pred_prob = logregcv.predict_proba(Xtest)\n",
    "print('Score:', logregcv.score(Xtest, ytest))\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_pred_prob[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title(\"ROC\")\n",
    "print('AUC', roc_auc_score(ytest, y_pred_prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Naive Bayes for text analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize project names and blurbs\n",
    "#vectorizer = TfidfVectorizer(min_df=1)\n",
    "vectorizer = CountVectorizer(min_df=2, max_df=2000)\n",
    "\n",
    "# project name\n",
    "Xn = vectorizer.fit_transform(dfn.name).tocsc()\n",
    "fn_names = vectorizer.get_feature_names()\n",
    "\n",
    "# project blurb\n",
    "dfn.blurb.fillna('', inplace=True)\n",
    "Xb = vectorizer.fit_transform(dfn.blurb).tocsc()\n",
    "fb_names = vectorizer.get_feature_names()\n",
    "\n",
    "y = dfn.succeeded.values.astype(np.int)\n",
    "\n",
    "print(Xn.shape, Xb.shape, y.shape, len(fn_names), len(fb_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple training without cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB for names\n",
    "\n",
    "# train-test split\n",
    "Xntrain, Xntest, ytrain, ytest = train_test_split(Xn, y)\n",
    "\n",
    "# Create instance of multinomial naive bayes\n",
    "mnb_n = MultinomialNB()\n",
    "\n",
    "# fit to training data\n",
    "mnb_n.fit(Xntrain, ytrain)\n",
    "\n",
    "print(\"Train set score:\", mnb_n.score(Xntrain, ytrain))\n",
    "print(\"Test set score:\", mnb_n.score(Xntest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB for blurbs\n",
    "\n",
    "# train-test split\n",
    "Xbtrain, Xbtest, ytrain, ytest = train_test_split(Xb, y)\n",
    "\n",
    "# Create instance of multinomial naive bayes\n",
    "mnb_b = MultinomialNB()\n",
    "\n",
    "# fit to training data\n",
    "mnb_b.fit(Xbtrain, ytrain)\n",
    "\n",
    "print(\"Train set score:\", mnb_b.score(Xbtrain, ytrain))\n",
    "print(\"Test set score:\", mnb_b.score(Xbtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the grid of parameters to search over\n",
    "param_grid = {'alpha':np.logspace(0.1, 100, 10)}\n",
    "              \n",
    "mnb = MultinomialNB()\n",
    "mnb_cv = GridSearchCV(mnb, param_grid, cv=5, verbose=1)\n",
    "mnb_cv.fit(Xn, y)\n",
    "\n",
    "print('Best alpha', mnb_cv.best_params_)\n",
    "print('Best score', mnb_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_cv.predict_proba(Xn)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = mnb_n.predict_proba(Xn)[:,1]\n",
    "pb = mnb_b.predict_proba(Xb)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = np.log(pn/(1-pn))\n",
    "xb = np.log(pb/(1-pb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xn, xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfd['xn'] = xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfd['xb'] = xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors.extend(['xn', 'xb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx = dfd[predictors]\n",
    "y = dfd.succeeded.values.astype(np.int)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(Xx, y)\n",
    "print(X.shape, Xtrain.shape, Xtest.shape, y.shape, ytrain.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(verbose=1, C=0.1)#, warm_start=True)\n",
    "\n",
    "logreg.fit(Xtrain, ytrain)\n",
    "#logreg.intercept_ = 2.299\n",
    "#logreg.coef_ = np.reshape(np.array([-0.6687]), (1,-1))\n",
    "print(logreg.intercept_, logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(Xtest)\n",
    "y_pred_prob = logreg.predict_proba(Xtest)\n",
    "print('Score:', logreg.score(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CV score:', cross_val_score(logreg, Xx, y, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logregcv.predict(Xtest)\n",
    "y_pred_prob = logregcv.predict_proba(Xtest)\n",
    "print('Score:', logregcv.score(Xtest, ytest))\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_pred_prob[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title(\"ROC\")\n",
    "print('AUC', roc_auc_score(ytest, y_pred_prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify score function to replace accuracy with precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Interpretability, based on rigorous statistical principles, minimal number of parameters, predictions of microstructures\n",
    "Well justified choice of optimization loss function base on rigorous statistical principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
